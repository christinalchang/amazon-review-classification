{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "import gzip\n",
    "import json\n",
    "import re\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/christinachang/Documents/ECS171/reviewClassifier'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'r')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "    \n",
    "    \n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF(\"../../../Downloads/AMAZON_FASHION_5.json.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>style</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 4, 2015</td>\n",
       "      <td>ALJ66O1Y6SLHA</td>\n",
       "      <td>B000K2PJ4K</td>\n",
       "      <td>{'Size:': ' Big Boys', 'Color:': ' Blue/Orange'}</td>\n",
       "      <td>Tonya B.</td>\n",
       "      <td>Great product and price!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1441324800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 4, 2015</td>\n",
       "      <td>ALJ66O1Y6SLHA</td>\n",
       "      <td>B000K2PJ4K</td>\n",
       "      <td>{'Size:': ' Big Boys', 'Color:': ' Black (3746...</td>\n",
       "      <td>Tonya B.</td>\n",
       "      <td>Great product and price!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1441324800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 4, 2015</td>\n",
       "      <td>ALJ66O1Y6SLHA</td>\n",
       "      <td>B000K2PJ4K</td>\n",
       "      <td>{'Size:': ' Big Boys', 'Color:': ' Blue/Gray L...</td>\n",
       "      <td>Tonya B.</td>\n",
       "      <td>Great product and price!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1441324800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 4, 2015</td>\n",
       "      <td>ALJ66O1Y6SLHA</td>\n",
       "      <td>B000K2PJ4K</td>\n",
       "      <td>{'Size:': ' Big Boys', 'Color:': ' Blue (37867...</td>\n",
       "      <td>Tonya B.</td>\n",
       "      <td>Great product and price!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1441324800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>09 4, 2015</td>\n",
       "      <td>ALJ66O1Y6SLHA</td>\n",
       "      <td>B000K2PJ4K</td>\n",
       "      <td>{'Size:': ' Big Boys', 'Color:': ' Blue/Pink'}</td>\n",
       "      <td>Tonya B.</td>\n",
       "      <td>Great product and price!</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1441324800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified  reviewTime     reviewerID        asin  \\\n",
       "0      5.0      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K   \n",
       "1      5.0      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K   \n",
       "2      5.0      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K   \n",
       "3      5.0      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K   \n",
       "4      5.0      True  09 4, 2015  ALJ66O1Y6SLHA  B000K2PJ4K   \n",
       "\n",
       "                                               style reviewerName  \\\n",
       "0   {'Size:': ' Big Boys', 'Color:': ' Blue/Orange'}     Tonya B.   \n",
       "1  {'Size:': ' Big Boys', 'Color:': ' Black (3746...     Tonya B.   \n",
       "2  {'Size:': ' Big Boys', 'Color:': ' Blue/Gray L...     Tonya B.   \n",
       "3  {'Size:': ' Big Boys', 'Color:': ' Blue (37867...     Tonya B.   \n",
       "4     {'Size:': ' Big Boys', 'Color:': ' Blue/Pink'}     Tonya B.   \n",
       "\n",
       "                 reviewText     summary  unixReviewTime vote image  \n",
       "0  Great product and price!  Five Stars      1441324800  NaN   NaN  \n",
       "1  Great product and price!  Five Stars      1441324800  NaN   NaN  \n",
       "2  Great product and price!  Five Stars      1441324800  NaN   NaN  \n",
       "3  Great product and price!  Five Stars      1441324800  NaN   NaN  \n",
       "4  Great product and price!  Five Stars      1441324800  NaN   NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3176, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate reviews\n",
    "df_nodup = df.drop_duplicates(subset = ['reviewText'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(doc):\n",
    "    \"\"\"\n",
    "    Input: A string of words.\n",
    "    Output: List of tokenized words that are all lowercase.\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize and make lowercase.\n",
    "    words = nltk.word_tokenize(doc)\n",
    "    words = [w.lower() for w in words]\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "def wordnet_pos(tag):\n",
    "    \"\"\"\n",
    "    Map a Brown POS tag to a WordNet POS tag. This is for lemmatization.\n",
    "    \"\"\"\n",
    "    \n",
    "    table = {\"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV, \"J\": wordnet.ADJ}\n",
    "    \n",
    "    # Default to a noun.\n",
    "    return table.get(tag[0], wordnet.NOUN)\n",
    "\n",
    "\n",
    "def lemmatize_text(words):\n",
    "    \"\"\"\n",
    "    Input: A list of tokenized words.\n",
    "    Output: A list of tokenized words that are lemmatized.\n",
    "    \"\"\"\n",
    "    \n",
    "    lemmatizer = nltk.WordNetLemmatizer()\n",
    "    word_tags = nltk.pos_tag(words)\n",
    "    words = [lemmatizer.lemmatize(w, wordnet_pos(t)) for (w, t) in word_tags]\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    \"\"\"\n",
    "    Input: A list of tokenized words.\n",
    "    Output: A list of tokenized words that have stopwords removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    words = [w for w in words if w not in stopwords]\n",
    "    \n",
    "    return words\n",
    "\n",
    "def clean_text(doc): \n",
    "    \"\"\"\n",
    "    Input: A string of words.\n",
    "    Output: A string of words that has been lemmatized, has the stopwords removed, and has the puncuation removed.\n",
    "    \"\"\"\n",
    "    \n",
    "    words = re.sub(\"< ?/?[a-z]+ ?>|\\n\", \"\", doc)\n",
    "    words = tokenize_text(words)\n",
    "    words = lemmatize_text(words)\n",
    "    words = remove_stopwords(words)\n",
    "    doc = [w for w in words if w.isalnum()]\n",
    "    doc = ' '.join(doc)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "def clean_df(df):\n",
    "    \"\"\"\n",
    "    Input: A dataframe with a column of reviews called 'reviewText'.\n",
    "    Output: The same dataframe as the input, but with an extra column called 'text' which has the \n",
    "            cleaned 'reviewText'.\n",
    "    \"\"\"\n",
    "    \n",
    "    text = df['reviewText']\n",
    "    df_clean = df.copy()\n",
    "    df_clean['text'] = [clean_text(str(i)) for i in text]\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relieved my Plantar Fascitis for 3 Days. Then the unbearable pain returned in full force. These were recommended by my Podiatrist.\n",
      "relieve plantar fascitis 3 day unbearable pain return full force recommend podiatrist\n"
     ]
    }
   ],
   "source": [
    "print(df['reviewText'][10])\n",
    "print(clean_text(df['reviewText'][10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love these sneakers. Light weight and comfortable even without socks.\n",
      "love sneaker light weight comfortable even without sock\n"
     ]
    }
   ],
   "source": [
    "print(df['reviewText'][300])\n",
    "print(clean_text(df['reviewText'][300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great product and price!</td>\n",
       "      <td>great product price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Waaay too small. Will use for futur children!</td>\n",
       "      <td>waaay small use futur child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Stays vibrant after many washes</td>\n",
       "      <td>stay vibrant many wash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My son really likes the pink. Ones which I was...</td>\n",
       "      <td>son really like pink one nervous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Waaay too small. Will use for future child.</td>\n",
       "      <td>waaay small use future child</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0                           Great product and price!   \n",
       "5      Waaay too small. Will use for futur children!   \n",
       "6                    Stays vibrant after many washes   \n",
       "8  My son really likes the pink. Ones which I was...   \n",
       "9        Waaay too small. Will use for future child.   \n",
       "\n",
       "                               text  \n",
       "0               great product price  \n",
       "5       waaay small use futur child  \n",
       "6            stay vibrant many wash  \n",
       "8  son really like pink one nervous  \n",
       "9      waaay small use future child  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "clean_df(df_nodup)[['reviewText', 'text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2656\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2657\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9980bc000253>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrip_accents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'unicode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'word'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2926\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2927\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2929\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2657\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2658\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2659\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2660\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode', analyzer='word', ngram_range=(1,3), norm='l2')\n",
    "\n",
    "tmp = df['text']\n",
    "\n",
    "vectorizer.fit(tmp)\n",
    "\n",
    "tmp_tfidf = vectorizer.transform(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3176x9341 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 101439 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
